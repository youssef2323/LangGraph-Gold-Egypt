# gold-eg-report-langgraph

> **Arabic, Egypt-only gold price reporter** â€” built with **LangGraph** (multi-agent flow) + **Streamlit** UI.  
> Searches Arabic web sources, extracts **EGP/gram** prices (18/21/24 karat), separates **Ø¨Ø¯ÙˆÙ†/Ø¨Ø§Ù„Ù…ØµÙ†Ø¹ÙŠØ©**, and generates a concise Arabic report via LLM.

---

## ğŸš€ Why this repo?
An interview-ready, minimal-yet-solid demo of **agentic workflows** using **LangGraph** â€” with a real use case (gold prices in Egypt, today).  
It proves you can:
- Design a **multi-agent** graph (`search â†’ fetch â†’ report`).
- Parse Arabic pages, normalize numbers, and **filter noise** reliably.
- Produce a clean **Arabic** report and a **Streamlit** dashboard.

---

## ğŸ§° Tech stack
- **LangGraph** (agentic state machine)
- **LangChain + Groq (langchain-groq)** for LLM calls
- **Streamlit** (Arabic UI)
- **DDGS** (DuckDuckGo search API)
- **BeautifulSoup + requests + tenacity** (scrape + robust retries)
- **pytz** (Africa/Cairo time), **pandas** (CSV export)

---

## ğŸ“¸ Screenshots

<p align="center">
  <img src="Screenshots/1.png" width="800" alt="Home">
</p>
<p align="center">
  <img src="Screenshots/2.png" width="800" alt="21k split">
</p>
<p align="center">
  <img src="Screenshots/3.png" width="800" alt="21k split">
</p>
<p align="center">
  <img src="Screenshots/4.png" width="800" alt="21k split">
</p>
```

---

## ğŸ—‚ Project structure
```
.
â”œâ”€ app.py               # Streamlit UI (Arabic), CSV/report downloads, 21k split rendering
â”œâ”€ agents.py            # search_agent, fetch_agent, report_agent (+ Groq wrapper)
â”œâ”€ graph.py             # LangGraph graph: search â†’ fetch â†’ report
â”œâ”€ prompts.py           # Strict Egypt-only Arabic reporting prompt
â”œâ”€ scraper.py           # Search + fetch + parse (EGP-only, year-guard, context check, Ù…ØµÙ†Ø¹ÙŠØ© flag)
â”œâ”€ utils.py             # now_cairo(), normalize_number(), helpers
â”œâ”€ requirements.txt
â””â”€ screenshots/         # (add PNGs here for the README)
```

---

## âš™ï¸ Setup
```bash
# Python 3.10 (as requested)
conda create -p venv python==3.10 -y
conda activate ./venv

pip install -r requirements.txt
```

Create a `.env` in the project root:
```bash
# .env
GROQ_API_KEY=your_api_key_here
# Optional: fallback region (kept EG only in app)
DEFAULT_REGION=EG
# Optional: number of sources
MAX_SOURCES=8
# Optional: override Groq model (defaults to llama-3.1-70b-versatile)
GROQ_MODEL=llama-3.1-70b-versatile
```

Run the app:
```bash
streamlit run app.py
```

---

## ğŸ•¸ How it works (LangGraph)
**Nodes**
1. **search_agent** â†’ Arabic web search (DDGS), EG-only link filter (drops ounce/USD/Turkey)
2. **fetch_agent** â†’ Fetch pages, parse **EGP/gram**, prefer **Ø§Ù„ÙŠÙˆÙ…**, compute stats + 21k split (Ø¨Ø¯ÙˆÙ†/Ø¨Ø§Ù„Ù…ØµÙ†Ø¹ÙŠØ©)
3. **report_agent** â†’ Build strict Arabic prompt & call Groq LLM â†’ final report

**State keys**
```python
{
  "query": str,           # e.g., "Ø³Ø¹Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„ÙŠÙˆÙ…"
  "region": "EG",         # hard-coded to Egypt in app.py
  "links": List[str],     # filtered URLs
  "pages": List[dict],    # fetch results (ok/error)
  "prices": List[dict],   # extracted rows (price, currency, karat, with_making, published_hint)
  "stats": dict,          # per-karat min/max/count
  "stats_wm": dict,       # "21:with"/"21:without" â†’ min/max/count
  "report": str           # final Arabic report text
}
```

**Flow (Mermaid)**
```mermaid
flowchart LR
  A[search_agent] --> B[fetch_agent] --> C[report_agent] --> D[END]
```

---

## âœ… Key features (Egypt-only, Arabic UX)
- **EGP/gram only** â€” no USD/ounce conversions
- **Year-guard** â€” prevents â€œ2025 Ø¬Ù†ÙŠÙ‡â€ false positives
- **Gold-context check** â€” accepts `<num> Ø¬Ù†ÙŠÙ‡` only in gold context
- **Ù…ØµÙ†Ø¹ÙŠØ© flag** â€” split **Ø¹ÙŠØ§Ø± 21** into **Ø¨Ø¯ÙˆÙ†/Ø¨Ø§Ù„Ù…ØµÙ†Ø¹ÙŠØ©**
- **Freshness preference** â€” uses simple date hints to prefer **Ø§Ù„ÙŠÙˆÙ…**
- **CSV & report downloads** â€” one click for auditing & sharing

---

## ğŸ§ª Quick test checklist
- Query: **Ø³Ø¹Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„ÙŠÙˆÙ…** â†’ links have no **xau-usd/oz/ounce/turkey**
- Table: all rows show **Ø¬Ù†ÙŠÙ‡/Ø¬Ø±Ø§Ù…**
- â€œÙ…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹â€: no year leaks; ranges look sensible
- â€œØªÙØµÙŠÙ„ Ø¹ÙŠØ§Ø± 21â€: shows **Ø¨Ø¯ÙˆÙ†/Ø¨Ø§Ù„Ù…ØµÙ†Ø¹ÙŠØ©** when available
- Report: says **ØºÙŠØ± Ù…ØªØ§Ø­** for 21k only if stats truly lack it



## ğŸ—º Roadmap (nice-to-have)
- Freshness badges (Ø§Ù„ÙŠÙˆÙ…/Ø£Ù…Ø³/ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ) per row
- Domain **whitelist/weighting** to stabilize sources
- Simple caching of page HTMLs to avoid re-scrapes
- Unit tests for `normalize_number` & the parser

---

## ğŸ›  Troubleshooting
- **Empty report / no links:** check internet/DuckDuckGo; raise `MAX_SOURCES`.
- **â€œGROQ_API_KEYâ€ missing:** add it to `.env`; restart terminal.
- **Model/tool error:** set `GROQ_MODEL=llama-3.1-70b-versatile` (supported) and upgrade `langchain-groq`.
- **Still seeing â€œ2025 Ø¬Ù†ÙŠÙ‡â€:** ensure you replaced `scraper.py` with the year-guard version.



---

## ğŸ“„ License
MIT (or your preference).




